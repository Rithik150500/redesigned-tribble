# Layer 2: Building the MCP Document Analysis Server

Now that we have our document processing pipeline and database ready, let's build the MCP server that will expose these documents to AI agents. This server acts as the bridge between your structured document database and the intelligent agents that will analyze them.

Think of this MCP server as a specialized librarian. The database is your library's catalog system, and the MCP server is the librarian who knows exactly how to find what you need and present it in the most useful way. When an agent asks for documents, the server doesn't just dump raw data - it carefully formats and structures the information to be maximally useful for analysis.

## Understanding the MCP Server Architecture

Before we write code, let me explain what we're building and why each piece matters. An MCP server needs to do several things well. It must expose tools that agents can discover and understand how to use. It must handle tool invocations by querying the database and formatting results appropriately. It must manage errors gracefully so that if something goes wrong, the agent receives useful feedback rather than cryptic failures. And it must maintain efficiency, because agents might make many requests during an analysis session.

The four tools we're exposing each serve a specific purpose in the analysis workflow. The list documents tool gives agents a catalog view so they can understand what's available and plan their investigation. The get documents tool provides rich, multi-layered access to complete documents, including both structural understanding through page summaries and immediate access to critical content through legally significant pages. The get page text tool enables targeted deep dives when agents need specific content beyond what was automatically surfaced. And the get page image tool provides visual analysis capability when text alone isn't sufficient.

## Creating the MCP Server

Let's build the server step by step, and I'll explain each design decision as we go.

```python
# legal_doc_mcp_server.py
from mcp.server.fastmcp import FastMCP
from database import LegalDocumentDatabase
import base64
from typing import Optional
import os

# Initialize the FastMCP server
# FastMCP uses Python type hints and docstrings to automatically generate
# tool definitions, making it easy to create well-documented MCP tools
mcp = FastMCP("legal-document-analysis")

# Initialize database connection
# We'll use a global database instance that all tools can access
# In production, you might want dependency injection or connection pooling
db = LegalDocumentDatabase()

@mcp.tool()
async def list_documents() -> str:
    """
    List all available legal documents in the data room.
    
    Returns a formatted summary of each document including:
    - Document ID (for use in other tools)
    - Filename
    - Document summary
    - Total page count
    - Number of legally significant pages
    
    This tool helps you understand what documents are available before
    conducting detailed analysis. Use this first to plan your investigation.
    """
    try:
        # Query the database for all documents
        documents = db.get_all_documents()
        
        if not documents:
            return "No documents found in the data room. Please ensure documents have been processed and added to the database."
        
        # Format the response for maximum agent comprehension
        # We want to give enough detail for decision-making but not overwhelm
        result_lines = [
            "=== LEGAL DOCUMENTS DATA ROOM ===",
            f"\nTotal Documents: {len(documents)}\n"
        ]
        
        for doc in documents:
            # Build a rich description for each document
            # The agent needs to understand: what is this, how big is it, and what's important
            doc_info = [
                f"üìÑ Document ID: {doc['doc_id']}",
                f"   Filename: {doc['filename']}",
                f"   Summary: {doc['summdesc'] or 'No summary available'}",
                f"   Pages: {doc['total_pages']} total, {doc['legally_significant_pages']} legally significant",
                ""  # Empty line for readability
            ]
            result_lines.extend(doc_info)
        
        result_lines.append(
            "\nTo analyze a document in detail, use the get_documents tool with the document ID."
        )
        
        return "\n".join(result_lines)
        
    except Exception as e:
        # Always provide useful error messages to the agent
        # The agent needs to understand what went wrong and how to proceed
        return f"Error listing documents: {str(e)}\nPlease check that the database is accessible and properly configured."


@mcp.tool()
async def get_documents(doc_ids: list[int]) -> str:
    """
    Get detailed content for one or more documents.
    
    This tool provides rich, multi-layered access to documents:
    1. All page summaries in order (showing document structure)
    2. Full text of all legally significant pages (immediate access to key content)
    
    This design lets you understand both the document's organization and its
    most important content without needing to request hundreds of pages individually.
    
    Args:
        doc_ids: List of document IDs to retrieve (from list_documents)
    
    Returns:
        Formatted document content with page summaries and significant page text
    """
    try:
        if not doc_ids:
            return "Error: doc_ids parameter is required. Please provide at least one document ID."
        
        results = []
        
        for doc_id in doc_ids:
            # Get document metadata
            doc = db.get_document(doc_id)
            
            if not doc:
                results.append(f"\n‚ùå Document ID {doc_id} not found.")
                continue
            
            # Build the document response in layers
            doc_sections = [
                f"\n{'='*70}",
                f"DOCUMENT: {doc['filename']} (ID: {doc_id})",
                f"{'='*70}",
                f"\nSUMMARY: {doc['summdesc']}",
                f"PAGES: {doc['total_pages']} total, {doc['legally_significant_pages']} legally significant\n"
            ]
            
            # Layer 1: All page summaries (structure and navigation)
            doc_sections.append("\n--- PAGE SUMMARIES (Document Structure) ---\n")
            
            all_pages = db.get_pages(doc_id)
            
            if all_pages:
                for page in all_pages:
                    # Mark legally significant pages visually
                    marker = "‚öñÔ∏è " if page['legally_significant'] else "   "
                    doc_sections.append(
                        f"{marker}Page {page['page_num']}: {page['summdesc']}"
                    )
            else:
                doc_sections.append("No pages found for this document.")
            
            # Layer 2: Full text of legally significant pages
            # This is the key intelligence - we automatically surface the most important content
            significant_pages = db.get_legally_significant_pages(doc_id)
            
            if significant_pages:
                doc_sections.append(
                    f"\n--- LEGALLY SIGNIFICANT PAGE CONTENT ---\n"
                    f"The following {len(significant_pages)} pages contain important legal provisions:\n"
                )
                
                for page in significant_pages:
                    doc_sections.extend([
                        f"\n{'‚îÄ'*70}",
                        f"PAGE {page['page_num']}: {page['summdesc']}",
                        f"{'‚îÄ'*70}\n",
                        page['page_text'] or "[No text extracted from this page]",
                        ""
                    ])
            else:
                doc_sections.append(
                    "\n--- LEGALLY SIGNIFICANT PAGE CONTENT ---\n"
                    "No pages were marked as legally significant in this document.\n"
                    "Use get_page_text to examine specific pages if needed."
                )
            
            results.append("\n".join(doc_sections))
        
        # Add usage guidance at the end
        results.append(
            "\n" + "="*70 + "\n"
            "ANALYSIS NOTES:\n"
            "- Pages marked with ‚öñÔ∏è contain legally significant provisions\n"
            "- Use get_page_text for additional pages not marked as significant\n"
            "- Use get_page_image (limited use) to examine visual layout if needed\n"
        )
        
        return "\n\n".join(results)
        
    except Exception as e:
        return f"Error retrieving documents: {str(e)}\nPlease verify the document IDs and database connectivity."


@mcp.tool()
async def get_page_text(doc_id: int, page_nums: list[int]) -> str:
    """
    Get the full text content of specific pages.
    
    Use this tool when you need to examine pages that weren't marked as
    legally significant, or when you want to see context around significant
    pages (e.g., pages immediately before/after an important clause).
    
    Args:
        doc_id: The document ID (from list_documents)
        page_nums: List of page numbers to retrieve (1-indexed)
    
    Returns:
        Full text content of the requested pages
    """
    try:
        if not page_nums:
            return "Error: page_nums parameter is required. Please provide at least one page number."
        
        # Get document info for context
        doc = db.get_document(doc_id)
        if not doc:
            return f"Error: Document ID {doc_id} not found."
        
        # Validate page numbers
        if any(p < 1 or p > doc['total_pages'] for p in page_nums):
            return f"Error: Invalid page numbers. Document has {doc['total_pages']} pages. Requested pages: {page_nums}"
        
        # Retrieve the pages
        pages = db.get_pages(doc_id, page_nums)
        
        if not pages:
            return f"Error: Could not retrieve pages {page_nums} from document {doc_id}."
        
        # Format response
        result_lines = [
            f"{'='*70}",
            f"DOCUMENT: {doc['filename']} (ID: {doc_id})",
            f"REQUESTED PAGES: {', '.join(map(str, page_nums))}",
            f"{'='*70}\n"
        ]
        
        for page in pages:
            result_lines.extend([
                f"{'‚îÄ'*70}",
                f"PAGE {page['page_num']}: {page['summdesc']}",
                f"{'‚îÄ'*70}\n",
                page['page_text'] or "[No text extracted from this page]",
                ""
            ])
        
        return "\n".join(result_lines)
        
    except Exception as e:
        return f"Error retrieving page text: {str(e)}"


@mcp.tool()
async def get_page_image(doc_id: int, page_nums: list[int]) -> str:
    """
    Get page images for visual analysis.
    
    ‚ö†Ô∏è LIMITED USE TOOL - Use sparingly as images consume significant tokens.
    
    Use this tool ONLY when:
    - Visual layout is important (tables, charts, diagrams)
    - You need to verify signature blocks or handwritten annotations
    - Text extraction seems incomplete or unclear
    - You need to understand document formatting or structure
    
    Try to exhaust text-based analysis before requesting images.
    
    Args:
        doc_id: The document ID (from list_documents)
        page_nums: List of page numbers to retrieve (1-indexed)
    
    Returns:
        Page images in base64 format with context information
    """
    try:
        if not page_nums:
            return "Error: page_nums parameter is required. Please provide at least one page number."
        
        # Get document info
        doc = db.get_document(doc_id)
        if not doc:
            return f"Error: Document ID {doc_id} not found."
        
        # Validate page numbers
        if any(p < 1 or p > doc['total_pages'] for p in page_nums):
            return f"Error: Invalid page numbers. Document has {doc['total_pages']} pages. Requested pages: {page_nums}"
        
        # Retrieve the pages
        pages = db.get_pages(doc_id, page_nums)
        
        if not pages:
            return f"Error: Could not retrieve pages {page_nums} from document {doc_id}."
        
        # Build response with images
        # Note: We return formatted text that describes what we're sending
        # The actual image data will be in the tool response content
        result_lines = [
            f"{'='*70}",
            f"DOCUMENT: {doc['filename']} (ID: {doc_id})",
            f"PAGE IMAGES RETRIEVED: {', '.join(map(str, page_nums))}",
            f"{'='*70}\n",
            "‚ö†Ô∏è USAGE NOTE: Images consume significant tokens. You have used this tool for:",
            f"   - Document {doc_id}: {len(page_nums)} pages\n"
        ]
        
        for page in pages:
            result_lines.extend([
                f"{'‚îÄ'*70}",
                f"PAGE {page['page_num']}: {page['summdesc']}",
                f"{'‚îÄ'*70}"
            ])
            
            # Convert image bytes to base64 for transmission
            if page['page_image']:
                image_b64 = base64.b64encode(page['page_image']).decode('utf-8')
                result_lines.append(f"\n[Image data: {len(image_b64)} bytes encoded]\n")
                # In a real implementation, you might return this in a structured format
                # that Claude can process as an actual image
            else:
                result_lines.append("\n[No image available for this page]\n")
        
        result_lines.extend([
            "",
            "TIP: Use get_page_text first for text-based analysis before requesting images.",
            "Reserve images for cases where visual layout is critical to understanding."
        ])
        
        return "\n".join(result_lines)
        
    except Exception as e:
        return f"Error retrieving page images: {str(e)}"


# Server initialization and startup
def main():
    """
    Run the MCP server.
    
    This server uses stdio transport, which means it communicates via
    standard input/output. This is ideal for local MCP servers that will
    be launched by MCP hosts like Claude Desktop or custom applications.
    """
    import asyncio
    
    # Run the server
    # The server will listen on stdin/stdout for JSON-RPC messages
    mcp.run(transport='stdio')


if __name__ == "__main__":
    main()
```

Now let me explain the key design decisions in this server, because understanding the "why" is as important as the "what."

## Understanding the Tool Response Formatting

The way we format tool responses is crucial for agent comprehension. Notice how each tool returns structured text with visual separators like equals signs and dashes. This isn't just aesthetic - it helps agents parse and understand the hierarchical structure of information. When an agent receives the response from get documents, it can clearly distinguish between the page summaries section and the legally significant content section. The visual markers help the agent understand "this is navigation information" versus "this is detailed content I should analyze."

The emoji markers serve a similar purpose. When we mark legally significant pages with the scales of justice emoji, we're creating a visual anchor that helps agents quickly identify important pages when scanning through summaries. This is particularly valuable when a document has dozens of pages - the agent can quickly spot the critical ones.

## The Layered Information Architecture

The get documents tool demonstrates an important principle: progressive disclosure of information. We give the agent three layers of understanding. The first layer is the document summary, which provides high-level context about what this document is and why it matters. The second layer is the page summaries, which show how the document is structured and what each page covers. The third layer is the full text of legally significant pages, which provides immediate access to the most important content without requiring additional tool calls.

This layered approach optimizes for agent efficiency. An agent can quickly understand a document's structure, identify relevant sections, and access critical content in a single tool call. If the agent needs more detail on non-significant pages, it can make targeted requests with get page text. This prevents the common problem of agents either getting too little information (requiring many follow-up calls) or too much information (overwhelming their context window with irrelevant content).

## Error Handling Philosophy

Notice how every tool includes comprehensive error handling. When something goes wrong, we don't just return a generic error message. We provide specific information about what failed and how to fix it. If a document ID doesn't exist, we say exactly that. If page numbers are out of range, we tell the agent the valid range. This helps agents recover gracefully from errors rather than getting stuck.

The error messages also guide the agent toward correct usage. When an agent tries to call get page text without providing page numbers, we don't just say "missing parameter" - we explain what parameter is required and how to use it. This makes the tools more discoverable and reduces the chance of agents making repeated mistakes.

## Testing Your MCP Server

Before we integrate this server with agents, let's create a simple test script to verify it works correctly. This will help you understand how MCP communication works and debug any issues before adding the complexity of the agent layer.

```python
# test_mcp_server.py
"""
Test script for the legal document analysis MCP server.

This script demonstrates how to interact with the MCP server programmatically.
It's useful for testing and debugging before integrating with agents.
"""

import subprocess
import json
import sys

def test_mcp_server():
    """
    Test the MCP server by sending tool invocation requests.
    
    This simulates what an MCP client (like a Deep Agent) would do when
    calling our tools.
    """
    print("Testing Legal Document Analysis MCP Server")
    print("=" * 60)
    
    # Start the MCP server as a subprocess
    # We'll communicate with it via stdin/stdout using JSON-RPC
    process = subprocess.Popen(
        ['python', 'legal_doc_mcp_server.py'],
        stdin=subprocess.PIPE,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        text=True,
        bufsize=1
    )
    
    def send_request(method: str, params: dict = None):
        """Send a JSON-RPC request to the server."""
        request = {
            "jsonrpc": "2.0",
            "id": 1,
            "method": method,
            "params": params or {}
        }
        
        request_json = json.dumps(request) + "\n"
        process.stdin.write(request_json)
        process.stdin.flush()
        
        # Read response
        response_line = process.stdout.readline()
        if response_line:
            return json.loads(response_line)
        return None
    
    try:
        # Test 1: List all documents
        print("\n1. Testing list_documents tool...")
        response = send_request("tools/call", {
            "name": "list_documents",
            "arguments": {}
        })
        
        if response and "result" in response:
            print("‚úì Success! Response:")
            # The actual content will be in the content array
            if "content" in response["result"]:
                for item in response["result"]["content"]:
                    if item["type"] == "text":
                        print(item["text"][:500] + "...\n")
        else:
            print("‚úó Failed to list documents")
            print(response)
        
        # Test 2: Get a specific document (assuming doc_id 1 exists)
        print("\n2. Testing get_documents tool...")
        response = send_request("tools/call", {
            "name": "get_documents",
            "arguments": {"doc_ids": [1]}
        })
        
        if response and "result" in response:
            print("‚úì Success! Retrieved document 1")
            if "content" in response["result"]:
                for item in response["result"]["content"]:
                    if item["type"] == "text":
                        print(item["text"][:500] + "...\n")
        else:
            print("‚úó Failed to get document")
            print(response)
        
        # Test 3: Get specific page text
        print("\n3. Testing get_page_text tool...")
        response = send_request("tools/call", {
            "name": "get_page_text",
            "arguments": {"doc_id": 1, "page_nums": [1, 2]}
        })
        
        if response and "result" in response:
            print("‚úì Success! Retrieved page text")
        else:
            print("‚úó Failed to get page text")
            print(response)
        
        print("\n" + "=" * 60)
        print("Testing complete!")
        
    except Exception as e:
        print(f"\n‚úó Error during testing: {e}")
    finally:
        # Clean up
        process.terminate()
        process.wait()

if __name__ == "__main__":
    # Make sure you've processed some documents first
    print("\nNote: This test assumes you have already run ingest_documents.py")
    print("and have at least one document in your database.\n")
    
    response = input("Have you processed documents? (yes/no): ")
    if response.lower() in ['yes', 'y']:
        test_mcp_server()
    else:
        print("\nPlease run ingest_documents.py first to populate the database.")
        print("Then run this test script again.")
```

This test script helps you verify that your MCP server is working before we build the agent layer. It simulates what an MCP client would do - sending JSON-RPC requests and receiving responses.

## Creating a Configuration File

Now let's create a configuration file that will let MCP hosts (like Claude Desktop or our future Deep Agent system) discover and connect to this server.

```python
# config.py
"""
Configuration for the legal document analysis MCP server.

This module provides configuration management for connecting the MCP server
to various hosts and managing operational parameters.
"""

import os
from pathlib import Path

# Database configuration
DATABASE_PATH = os.getenv("LEGAL_DOC_DB_PATH", "legal_documents.db")

# API keys (for future use if we add additional capabilities)
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")

# Server configuration
SERVER_NAME = "legal-document-analysis"
SERVER_VERSION = "1.0.0"

# Tool usage limits (for future implementation of usage tracking)
MAX_IMAGE_REQUESTS_PER_SESSION = 10
MAX_PAGES_PER_IMAGE_REQUEST = 5

def get_mcp_config():
    """
    Generate MCP server configuration for various hosts.
    
    This returns configuration in the format expected by MCP hosts
    like Claude Desktop.
    """
    return {
        "mcpServers": {
            SERVER_NAME: {
                "command": "python",
                "args": [
                    str(Path(__file__).parent / "legal_doc_mcp_server.py")
                ],
                "env": {
                    "LEGAL_DOC_DB_PATH": DATABASE_PATH
                }
            }
        }
    }

def print_claude_desktop_config():
    """
    Print configuration instructions for Claude Desktop.
    
    Users can copy this to their Claude Desktop configuration file.
    """
    config = get_mcp_config()["mcpServers"][SERVER_NAME]
    
    # Get absolute path for the configuration
    server_path = Path(__file__).parent / "legal_doc_mcp_server.py"
    
    print("\n" + "="*70)
    print("CLAUDE DESKTOP CONFIGURATION")
    print("="*70)
    print("\nAdd this to your claude_desktop_config.json file:")
    print("\n{")
    print('  "mcpServers": {')
    print(f'    "{SERVER_NAME}": {{')
    print(f'      "command": "python",')
    print(f'      "args": ["{server_path.absolute()}"]')
    print('    }')
    print('  }')
    print("}\n")
    print("Location of config file:")
    print("  macOS: ~/Library/Application Support/Claude/claude_desktop_config.json")
    print("  Windows: %APPDATA%\\Claude\\claude_desktop_config.json")
    print("\n" + "="*70 + "\n")

if __name__ == "__main__":
    print_claude_desktop_config()
```

You can run this configuration script to get the exact configuration you need to add to Claude Desktop's config file, with the correct absolute paths for your system.

## Understanding MCP Server Lifecycle

Now that we have the code, let me explain how this server actually works when it's running. When an MCP host like Claude Desktop starts your server, it launches the Python process and establishes a communication channel via stdin and stdout. The server then goes through an initialization sequence where it exchanges capability information with the host. The server announces that it provides tools, and lists which tools are available. The host can then call those tools at any time by sending JSON-RPC requests.

When the host calls a tool, the request includes the tool name and arguments. Your server's tool function executes, queries the database, formats the response, and returns it to the host. The host then provides that response to the AI agent as context for continuing its work. This cycle repeats as the agent conducts its analysis, making multiple tool calls to gather information.

The stdio transport means all communication happens through standard input and output, which is why it's absolutely critical that your server never writes anything to stdout except JSON-RPC messages. Any print statements or logging to stdout would corrupt the message stream and break communication. That's why in production you'd want to configure logging to write to stderr or to a file instead.

## Next Steps and Validation

Before moving on to Layer 3 (the Deep Agent system), you should validate that this MCP server works correctly. Here's how to do that systematically.

First, make sure you've processed at least one document through your ingestion pipeline. Run the ingest documents script with a sample PDF in your data room folder. This populates your database with test data.

Second, test the MCP server directly using the test script I provided. This verifies that the server can start, accept tool calls, query the database, and return formatted responses. If you encounter errors at this stage, they're much easier to debug than after adding the agent layer.

Third, if you want to test with Claude Desktop, add the server configuration to your Claude Desktop config file and restart the application. You should see the tools appear in Claude's interface, and you can try asking Claude to list documents or analyze specific ones. This gives you a feel for how agents will interact with your server.

Once you've validated that the MCP server works correctly, we'll be ready to build Layer 3 - the Deep Agent system that orchestrates the analysis using these tools. The agent layer will add planning, delegation, and sophisticated decision-making on top of these foundational tools we've built.

Does this MCP server implementation make sense? Would you like me to clarify anything about how the tools work, how the server communicates, or how to test it before we move on to building the Deep Agents?
